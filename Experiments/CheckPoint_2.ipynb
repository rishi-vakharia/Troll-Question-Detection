{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Imports","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\ndf_train = pd.read_csv('/kaggle/input/yahoo-troll-question-detection/train_df.csv')\ndf_test = pd.read_csv('/kaggle/input/yahoo-troll-question-detection/test_df.csv')\n\nprint('Train shape: ', df_train.shape)\nprint('Test shape: ', df_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing","metadata":{}},{"cell_type":"code","source":"# import re\n# from tqdm import tqdm\n# tqdm.pandas()\n\n# def clean_text(text):\n#     words = word_tokenize(text) # Tokenization\n#     tagged_words = pos_tag(words) # POS tagging\n\n#     text = re.sub(r'[^a-zA-Z0-9\\s]', '', text) # Removing every character that is not alphanumeric\n#     text = re.sub(r'[0-9]+', '#', text) # Replacing every number with '#'\n    \n#     text = ' '.join([f'{stemmer.stem(tagged_word[0])}_{tagged_word[1]}' for tagged_word in tagged_words]) # Stemming and detokenization\n#     return text\n\n# def clean_df(df):\n#     df['question_text_cleaned'] = '' # Create a new empty column\n#     df['question_text_cleaned'] = df['question_text'].progress_apply(lambda x: clean_text(x))\n\n\n# clean_df(df_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Word2Vec: Average of word vectors","metadata":{}},{"cell_type":"code","source":"# from gensim.models import Word2Vec\n# from nltk.tokenize import word_tokenize\n\n# train_x = [word_tokenize(question) for question in train_x]\n# val_x = [word_tokenize(question) for question in val_x]\n# model = Word2Vec(train_x, min_count=4)\n\n# train_x_vectors = [np.zeros(model.wv.vector_size)] * len(train_x)\n# val_x_vectors = [np.zeros(model.wv.vector_size)] * len(val_x)\n\n# for i in range(len(train_x)):\n#     train_x[i] = [word for word in train_x[i] if word in model.wv.index_to_key]\n#     if(train_x[i] != []):\n#         train_x_vectors[i] = np.mean(model.wv[train_x[i]], axis=0) \n    \n# for i in range(len(val_x)):\n#     val_x[i] = [word for word in val_x[i] if word in model.wv.index_to_key]\n#     if(val_x[i] != []):\n#         val_x_vectors[i] = np.mean(model.wv[val_x[i]], axis=0) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## TF-IDF","metadata":{}},{"cell_type":"code","source":"import re, string\nre_tok = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\ndef tokenize(s): return re_tok.sub(r' \\1 ', s).split()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nvectorizer = TfidfVectorizer(ngram_range=(1,4), tokenizer=tokenize, min_df=3, max_df=0.9, strip_accents='unicode', use_idf=True, smooth_idf=True, sublinear_tf=True)\nvectorizer.fit(pd.concat([df_train['question_text'], df_test['question_text']]))\n\n\nX = vectorizer.transform(df_train['question_text'])\ny = df_train['target'].values\n\nX_test = vectorizer.transform(df_test['question_text'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## NB Features","metadata":{}},{"cell_type":"markdown","source":"We took reference from this research paper: https://nlp.stanford.edu/pubs/sidaw12_simple_sentiment.pdf","metadata":{}},{"cell_type":"code","source":"from sklearn.base import BaseEstimator, TransformerMixin\nfrom scipy.sparse import csr_matrix\n\nclass NBTransformer(BaseEstimator, TransformerMixin):\n    def __init__(self, alpha=1):\n        self.r = None\n        self.alpha = alpha\n\n    def fit(self, X, y):\n        # store smoothed log count ratio\n        p = self.alpha + X[y==1].sum(0)\n        q = self.alpha + X[y==0].sum(0)\n        self.r = csr_matrix(np.log(\n            (p / (self.alpha + (y==1).sum())) /\n            (q / (self.alpha + (y==0).sum()))\n        ))\n        return self\n\n    def transform(self, X, y=None):\n        return X.multiply(self.r)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nb_transformer = NBTransformer(alpha=1).fit(X, y)\n\nX_nb = nb_transformer.transform(X)\nX_test_nb = nb_transformer.transform(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Cross Validation & Testing","metadata":{}},{"cell_type":"markdown","source":"### 1. Logistic Regression","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nfrom sklearn.linear_model import LogisticRegression\n\nDATA_SPLIT_SEED = 42\nmodels = []\ntrain_meta = np.zeros(X_nb.shape[0])\ntest_meta = np.zeros(X_test_nb.shape[0])\nsplits = list(StratifiedKFold(n_splits=20, shuffle=True, random_state=DATA_SPLIT_SEED).split(df_train, y))\nfor idx, (train_idx, valid_idx) in enumerate(splits):\n    X_train = X_nb[train_idx]\n    y_train = y[train_idx]\n    X_val = X_nb[valid_idx]\n    y_val = y[valid_idx]\n    model = LogisticRegression(solver='lbfgs', dual=False, class_weight='balanced', C=0.5, max_iter=100)\n    model.fit(X_train, y_train)\n    models.append(model)\n    valid_pred = model.predict_proba(X_val)\n    train_meta[valid_idx] = valid_pred[:,1]\n    test_meta += model.predict_proba(X_test_nb)[:,1] / len(splits)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score, roc_auc_score\n\ndef threshold_search(y_true, y_proba):\n    best_threshold = 0\n    best_score = 0\n    for threshold in [i * 0.01 for i in range(100)]:\n        score = f1_score(y_true=y_true, y_pred=y_proba > threshold)\n        if score > best_score:\n            best_threshold = threshold\n            best_score = score\n    search_result = {'threshold': best_threshold, 'f1': best_score}\n    return search_result","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(roc_auc_score(y, train_meta))\nsearch_result = threshold_search(y, train_meta)\nprint(search_result)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.drop(columns=['question_text'], inplace=True)\ndf_test['target'] = (test_meta > search_result['threshold']).astype(int)\ndf_test.to_csv('/kaggle/working/submission_lr.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2. Multinomial Naive Bayes","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nX_nb_scaled = scaler.fit_transform(X_nb.toarray())\nX_test_nb_scaled = scaler.transform(X_test_nb.toarray())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nfrom sklearn.naive_bayes import MultinomialNB\n\nDATA_SPLIT_SEED = 42\nmodels = []\ntrain_meta = np.zeros(X_nb.shape[0])\ntest_meta = np.zeros(X_test_nb.shape[0])\nsplits = list(StratifiedKFold(n_splits=20, shuffle=True, random_state=DATA_SPLIT_SEED).split(df_train, y))\nfor idx, (train_idx, valid_idx) in enumerate(splits):\n    X_train = X_nb_scaled[train_idx]\n    y_train = y[train_idx]\n    X_val = X_nb_scaled[valid_idx]\n    y_val = y[valid_idx]\n    model = MultinomialNB()\n    model.fit(X_train, y_train)\n    models.append(model)\n    valid_pred = model.predict_proba(X_val)\n    train_meta[valid_idx] = valid_pred[:,1]\n    test_meta += model.predict_proba(X_test_nb_scaled)[:,1] / len(splits)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score, roc_auc_score\n\ndef threshold_search(y_true, y_proba):\n    best_threshold = 0\n    best_score = 0\n    for threshold in [i * 0.01 for i in range(100)]:\n        score = f1_score(y_true=y_true, y_pred=y_proba > threshold)\n        if score > best_score:\n            best_threshold = threshold\n            best_score = score\n    search_result = {'threshold': best_threshold, 'f1': best_score}\n    return search_result","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(roc_auc_score(y, train_meta))\nsearch_result = threshold_search(y, train_meta)\nprint(search_result)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.drop(columns=['question_text'], inplace=True)\ndf_test['target'] = (test_meta > search_result['threshold']).astype(int)\ndf_test.to_csv('/kaggle/working/submission_mnb.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3. Linear SVM","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nfrom sklearn.svm import LinearSVC\n\nDATA_SPLIT_SEED = 42\nmodels = []\ntrain_meta = np.zeros(X_nb.shape[0])\ntest_meta = np.zeros(X_test_nb.shape[0])\nsplits = list(StratifiedKFold(n_splits=20, shuffle=True, random_state=DATA_SPLIT_SEED).split(df_train, y))\nfor idx, (train_idx, valid_idx) in enumerate(splits):\n    X_train = X_nb[train_idx]\n    y_train = y[train_idx]\n    X_val = X_nb[valid_idx]\n    y_val = y[valid_idx]\n    model = LinearSVC(class_weight='balanced')\n    model.fit(X_train, y_train)\n    models.append(model)\n    valid_pred = model.predict(X_val)\n    train_meta[valid_idx] = valid_pred\n    test_meta += model.predict(X_test_nb) / len(splits)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f1_score(y_true=y, y_pred=train_meta)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.drop(columns=['question_text'], inplace=True)\ndf_test['target'] = (test_meta).astype(int)\ndf_test.to_csv('/kaggle/working/submission_svm.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4. Random Forest","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nfrom sklearn.ensemble import RandomForestClassifier\n\nDATA_SPLIT_SEED = 42\nmodels = []\ntrain_meta = np.zeros(X_nb.shape[0])\ntest_meta = np.zeros(X_test_nb.shape[0])\nsplits = list(StratifiedKFold(n_splits=20, shuffle=True, random_state=DATA_SPLIT_SEED).split(df_train, y))\nfor idx, (train_idx, valid_idx) in enumerate(splits):\n    X_train = X_nb[train_idx]\n    y_train = y[train_idx]\n    X_val = X_nb[valid_idx]\n    y_val = y[valid_idx]\n    model = RandomForestClassifier(n_estimators=20, min_samples_leaf=20, class_weight='balanced')\n    model.fit(X_train, y_train)\n    models.append(model)\n    valid_pred = model.predict_proba(X_val)\n    train_meta[valid_idx] = valid_pred[:,1]\n    test_meta += model.predict_proba(X_test_nb)[:,1] / len(splits)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score, roc_auc_score\n\ndef threshold_search(y_true, y_proba):\n    best_threshold = 0\n    best_score = 0\n    for threshold in [i * 0.01 for i in range(100)]:\n        score = f1_score(y_true=y_true, y_pred=y_proba > threshold)\n        if score > best_score:\n            best_threshold = threshold\n            best_score = score\n    search_result = {'threshold': best_threshold, 'f1': best_score}\n    return search_result","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(roc_auc_score(y, train_meta))\nsearch_result = threshold_search(y, train_meta)\nprint(search_result)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.drop(columns=['question_text'], inplace=True)\ndf_test['target'] = (test_meta > search_result['threshold']).astype(int)\ndf_test.to_csv('/kaggle/working/submission_rf.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}